nohup: ignoring input
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:  33%|███▎      | 1/3 [00:00<00:00,  9.57it/s]Downloading shards:  67%|██████▋   | 2/3 [00:00<00:00,  8.97it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00,  9.10it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00,  9.12it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [01:18<02:37, 78.90s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [02:33<01:16, 76.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [03:43<00:00, 73.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [03:43<00:00, 74.65s/it]
finish loading model..
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:03<?, ?it/s]
Generating!
Traceback (most recent call last):
  File "inference.py", line 285, in <module>
    fire.Fire(main)
  File "/usr/local/lib/python3.8/dist-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/usr/local/lib/python3.8/dist-packages/fire/core.py", line 475, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/usr/local/lib/python3.8/dist-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "inference.py", line 271, in main
    output = generator(instruction = prompt,
  File "inference.py", line 98, in generator
    generation_output = model.generate(
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/transformers/src/transformers/generation/utils.py", line 1704, in generate
    return self.sample(
  File "/transformers/src/transformers/generation/utils.py", line 2786, in sample
    outputs = self(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/transformers/src/transformers/models/mistral/modeling_mistral.py", line 1048, in forward
    outputs = self.model(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/transformers/src/transformers/models/mistral/modeling_mistral.py", line 891, in forward
    attention_mask = self._prepare_decoder_attention_mask(
  File "/transformers/src/transformers/models/mistral/modeling_mistral.py", line 799, in _prepare_decoder_attention_mask
    combined_attention_mask = _make_sliding_window_causal_mask(
  File "/transformers/src/transformers/models/mistral/modeling_mistral.py", line 81, in _make_sliding_window_causal_mask
    tensor = torch.full(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5829.73 GiB. GPU 0 has a total capacty of 79.15 GiB of which 64.73 GiB is free. Process 2267318 has 14.41 GiB memory in use. Of the allocated memory 13.77 GiB is allocated by PyTorch, and 164.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
